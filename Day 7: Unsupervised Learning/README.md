# Day 7: Unsupervised Learning

## Goal:
The goal of this session is to introduce students to **unsupervised learning methods**, particularly clustering and dimensionality reduction techniques, and guide them through practical implementations using K-Means, Hierarchical Clustering, and Principal Component Analysis (PCA).

---

## Topics Covered:

### 1. **Introduction to Unsupervised Learning**
- Difference between **supervised** and **unsupervised** learning.
- Overview of clustering algorithms and dimensionality reduction techniques.
- Common use cases of unsupervised learning (e.g., customer segmentation, anomaly detection).

### 2. **Clustering Algorithms**
   - **K-Means Clustering**: A method to partition data into K distinct clusters.
   - **Hierarchical Clustering**: A method to build a hierarchy of clusters, visualized using a dendrogram.

### 3. **Dimensionality Reduction**
   - **Principal Component Analysis (PCA)**: A method to reduce the dimensionality of data by projecting it onto a lower-dimensional space while retaining as much information as possible.

### 4. **Hands-on Activities**:
- **K-Means Clustering**: Implement and visualize K-Means clusters on the Iris dataset.
- **Hierarchical Clustering**: Build and visualize hierarchical clusters and dendrograms.
- **PCA**: Apply PCA on the Iris dataset and visualize the data in 2D space.

---

## Notebooks:

1. **Part1_Unsupervised_Learning.ipynb**:
   - Introduction to the concepts of unsupervised learning.
   - Difference between supervised and unsupervised learning.
   - Real-world applications and benefits of unsupervised learning methods.

2. **Part2_K-Means_Clustering.ipynb**:
   - Detailed implementation of K-Means Clustering on the Iris dataset.
   - Visualization of clusters and evaluation using the **Elbow Method** to find the optimal number of clusters.

3. **Part3_Hierarchical_Clustering.ipynb**:
   - Implementation of hierarchical clustering using **Agglomerative Clustering**.
   - Visualization of hierarchical clusters using a **dendrogram**.
   
4. **Part4_Principal_Component_Analysis.ipynb**:
   - Implementation of **PCA** for dimensionality reduction on the Iris dataset.
   - Visualization of the dataset in 2D space using the first two principal components.
   - Examination of the explained variance by the principal components.

---

## Key Learning Outcomes:
- Understand the difference between **supervised** and **unsupervised** learning.
- Implement and evaluate clustering techniques like **K-Means** and **Hierarchical Clustering**.
- Learn how to use **Principal Component Analysis (PCA)** for dimensionality reduction.
- Visualize clusters and the results of PCA for easier understanding of high-dimensional datasets.

---

## Resources:
- [Scikit-learn Clustering Documentation](https://scikit-learn.org/stable/modules/clustering.html)
- [PCA and Dimensionality Reduction](https://scikit-learn.org/stable/modules/decomposition.html#pca)

---
---